[{"input_text":"Selecting multiple files according to timestamp with globI have a directory with 7000 daily .tif files, spanning from 2002 to 2022. Each file has a respective indication of its timestamp, in the yyyy\/mm\/dd format, as: My_file_20020513.tif\nI'm trying to select the file paths according to their respective month, i.e. all files from January, all files from February, and so on.\nI thought using a simple wildcard showing my month of interest would solve the problem, such as:\njanuary_files = glob.glob('My_folder\/My_file_*01*.tif')\n\nBut this ended up selecting all files that have a number 01 on its string, such as all the first days of a month, and even October's days that starts with a 1.\nIs there a way I can use glob for selecting the file paths for a specific month only?","output_text":"Use ? to match a single character. Then you can use four ? to match any year.\njanuary_files = glob.glob('My_folder\/My_file_????01*.tif')"},{"input_text":"how to setup\/write to the aws log group from a fargate task?I have setting up a fargate task via cloudformation template ( see sample below) , the code for the task is in script.py file below. I successfully set up the task, now i want write logs to the cloudwatch. I have set up a log group while setting up the fargate task , and planning to use logger in python to write logs. how do i write to the aws log group i have created with my fargate task, from script.py using logger in python.\nAWSTemplateFormatVersion: 2010-09-09\nDescription: An example CloudFormation template for Fargate.\nParameters:\n  VPC:\n    Type: AWS::EC2::VPC::Id\n  SubnetA:\n    Type: AWS::EC2::Subnet::Id\n  SubnetB:\n    Type: AWS::EC2::Subnet::Id\n  Image:\n    Type: String\n    Default: 123456789012.dkr.ecr.region.amazonaws.com\/image:tag\nResources: \n  Cluster:\n    Type: AWS::ECS::Cluster\n    Properties:\n      ClusterName: !Join ['', [!Ref ServiceName, Cluster]]\n\n  TaskDefinition:\n    Type: AWS::ECS::TaskDefinition\n    DependsOn: LogGroup\n    Properties:\n      Family: !Join ['', [!Ref ServiceName, TaskDefinition]]\n      NetworkMode: awsvpc\n      RequiresCompatibilities:\n        - FARGATE\n      Cpu: 256\n      Memory: 2GB\n      ExecutionRoleArn: !Ref ExecutionRole\n      TaskRoleArn: !Ref TaskRole\n      ContainerDefinitions:\n        - Name: !Ref ServiceName\n          Image: !Ref Image\n          LogConfiguration:\n            LogDriver: awslogs\n            Options:\n              awslogs-group: '\/ecs\/my_log_group'\n              awslogs-region: 'us-east-1'\n              awslogs-stream-prefix: ecs-myfargatetask\n\n\n\nscript.py\nimport logging\n\nlogger = logging.getlogger('...')\n\nlogger.info('logging working')","output_text":"You just need to configure your Python logger to output to STDOUT\/STDERR (which I believe is what it does by default). The console output of the main process of your docker container in ECS is what is sent to CloudWatch Logs."}]